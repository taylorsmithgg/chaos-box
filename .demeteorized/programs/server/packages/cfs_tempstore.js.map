{"version":3,"sources":["cfs:tempstore/tempStore.js"],"names":[],"mappings":";;;;;;;;;;;;;;;;;AAAA,sB;AACA,E;AACA,8E;AACA,8E;AACA,0E;AACA,4E;AACA,4E;AACA,E;AACA,2E;AACA,2E;AACA,4D;AACA,E;AACA,+E;AACA,kD;;AAEA,kE;AACA,sD;;AAEA,8E;AACA,oD;;AAEA,2B;AACA,yB;AACA,iB;AACA,U;AACA,0B;AACA,G;AACA,kC;;AAEA,iH;AACA,oF;;AAEA,G;AACA,iC;AACA,yB;AACA,0B;AACA,W;AACA,4E;AACA,E;AACA,oB;AACA,0G;AACA,+E;AACA,E;AACA,0E;AACA,0D;AACA,Q;AACA,2E;AACA,mE;AACA,kF;AACA,M;AACA,E;AACA,0E;AACA,G;AACA,4B;;AAEA,oF;AACA,4E;AACA,2B;AACA,yB;;AAEA,mC;;AAEA,0E;AACA,mD;AACA,uF;AACA,2E;AACA,4E;;AAEA,qB;AACA,iF;AACA,yC;;AAEA,yB;AACA,qF;AACA,U;AACA,gH;AACA,G;;AAEA,oF;AACA,C;;AAEA,mC;AACA,6B;AACA,+D;AACA,G;AACA,C;;AAEA,oC;AACA,+E;AACA,sH;AACA,G;;AAEA,Y;AACA,oE;AACA,4E;AACA,0F;AACA,M;;AAEA,wB;;AAEA,G;AACA,qB;AACA,W;AACA,mC;AACA,4C;AACA,G;AACA,0B;AACA,6B;AACA,E;;AAEA,G;AACA,yB;AACA,2B;AACA,wB;AACA,W;AACA,gE;AACA,E;AACA,+D;AACA,qC;AACA,G;AACA,qD;AACA,2C;AACA,wG;;AAEA,yD;AACA,iC;AACA,2C;AACA,qB;AACA,e;AACA,6B;AACA,M;AACA,a;AACA,mB;AACA,6C;AACA,O;AACA,K;AACA,K;;AAEA,yC;AACA,2D;AACA,E;;AAEA,G;AACA,8B;AACA,+B;AACA,qF;AACA,G;AACA,yC;AACA,gG;AACA,oB;AACA,E;;AAEA,G;AACA,iC;AACA,2B;AACA,4C;AACA,qD;AACA,G;AACA,iE;AACA,kB;AACA,mF;AACA,6E;AACA,E;;AAEA,G;AACA,kC;AACA,U;AACA,2B;AACA,4E;AACA,wD;AACA,G;AACA,mE;AACA,kB;;AAEA,2E;AACA,iB;;AAEA,0D;AACA,gD;;AAEA,e;AACA,+B;;AAEA,mC;AACA,wB;AACA,0C;AACA,K;;AAEA,kB;;AAEA,uB;AACA,iE;AACA,8D;AACA,oE;AACA,O;;AAEA,kD;AACA,yC;;AAEA,G;AACA,E;;AAEA,G;AACA,iC;AACA,U;AACA,6E;AACA,wD;AACA,G;AACA,0D;AACA,kB;;AAEA,2E;AACA,iB;;AAEA,+C;AACA,uB;AACA,iE;AACA,wH;AACA,oE;AACA,O;;AAEA,0C;AACA,yC;AACA,K;AACA,E;;AAEA,G;AACA,yC;AACA,U;AACA,8D;AACA,qC;AACA,qC;AACA,E;AACA,qD;AACA,8C;AACA,mC;AACA,iD;AACA,0C;AACA,iF;AACA,wF;AACA,E;AACA,6F;AACA,G;AACA,6D;AACA,kB;;AAEA,2E;AACA,iB;;AAEA,0D;AACA,uD;;AAEA,oD;AACA,+E;;AAEA,yE;AACA,uC;;AAEA,sC;AACA,uD;;AAEA,8C;AACA,gF;AACA,6B;AACA,uB;AACA,uB;AACA,sC;AACA,uB;AACA,U;AACA,qB;AACA,G;;AAEA,4E;AACA,8E;AACA,2B;AACA,2E;AACA,U;AACA,sC;AACA,mF;AACA,0C;AACA,2E;;AAEA,4C;AACA,kD;;AAEA,4C;AACA,4E;;AAEA,oD;AACA,iD;AACA,mC;AACA,oB;AACA,gD;AACA,6C;;AAEA,6B;AACA,qE;;AAEA,e;AACA,2E;;AAEA,6B;AACA,kC;AACA,yC;AACA,sF;;AAEA,mD;AACA,sD;AACA,qC;AACA,8C;AACA,c;AACA,yE;AACA,mE;AACA,kD;AACA,O;;AAEA,8B;AACA,+B;;AAEA,2B;AACA,8D;AACA,4C;;AAEA,2C;AACA,sD;AACA,Y;AACA,gD;AACA,yD;AACA,K;AACA,K;;AAEA,gB;AACA,4C;AACA,mE;AACA,uC;AACA,K;;AAEA,qB;AACA,E;;AAEA,G;AACA,yC;AACA,W;AACA,6C;AACA,4C;AACA,G;AACA,I;AACA,mD;AACA,2E;AACA,iB;;AAEA,0D;AACA,sD;;AAEA,kF;;AAEA,0E;AACA,uG;AACA,oD;;AAEA,qC;AACA,kD;AACA,mD;AACA,mF;AACA,4B;AACA,yB;AACA,kB;AACA,O;AACA,G;;AAEA,2B;AACA,+C;;AAEA,qF;AACA,uB;AACA,qD;AACA,oD;AACA,G;;AAEA,+B;AACA,wB;AACA,E","file":"/packages/cfs:tempstore.js","sourcesContent":["// ##Temporary Storage\n//\n// Temporary storage is used for chunked uploads until all chunks are received\n// and all copies have been made or given up. In some cases, the original file\n// is stored only in temporary storage (for example, if all copies do some\n// manipulation in beforeSave). This is why we use the temporary file as the\n// basis for each saved copy, and then remove it after all copies are saved.\n//\n// Every chunk is saved as an individual temporary file. This is safer than\n// attempting to write multiple incoming chunks to different positions in a\n// single temporary file, which can lead to write conflicts.\n//\n// Using temp files also allows us to easily resume uploads, even if the server\n// restarts, and to keep the working memory clear.\n\n// The FS.TempStore emits events that others are able to listen to\nvar EventEmitter = Npm.require('events').EventEmitter;\n\n// We have a special stream concating all chunk files into one readable stream\nvar CombinedStream = Npm.require('combined-stream');\n\n/** @namespace FS.TempStore\n * @property FS.TempStore\n * @type {object}\n * @public\n * *it's an event emitter*\n */\nFS.TempStore = new EventEmitter();\n\n// Create a tracker collection for keeping track of all chunks for any files that are currently in the temp store\nvar tracker = FS.TempStore.Tracker = new Meteor.Collection('cfs._tempstore.chunks');\n\n/**\n * @property FS.TempStore.Storage\n * @type {StorageAdapter}\n * @namespace FS.TempStore\n * @private\n * This property is set to either `FS.Store.FileSystem` or `FS.Store.GridFS`\n *\n * __When and why:__\n * We normally default to `cfs-filesystem` unless its not installed. *(we default to gridfs if installed)*\n * But if `cfs-gridfs` and `cfs-worker` is installed we default to `cfs-gridfs`\n *\n * If `cfs-gridfs` and `cfs-filesystem` is not installed we log a warning.\n * the user can set `FS.TempStore.Storage` them selfs eg.:\n * ```js\n *   // Its important to set `internal: true` this lets the SA know that we\n *   // are using this internally and it will give us direct SA api\n *   FS.TempStore.Storage = new FS.Store.GridFS('_tempstore', { internal: true });\n * ```\n *\n * > Note: This is considered as `advanced` use, its not a common pattern.\n */\nFS.TempStore.Storage = null;\n\n// We will not mount a storage adapter until needed. This allows us to check for the\n// existance of FS.FileWorker, which is loaded after this package because it\n// depends on this package.\nfunction mountStorage() {\n\n  if (FS.TempStore.Storage) return;\n\n  // XXX: We could replace this test, testing the FS scope for grifFS etc.\n  // This is on the todo later when we get \"stable\"\n  if (Package[\"cfs:gridfs\"] && (Package[\"cfs:worker\"] || !Package[\"cfs:filesystem\"])) {\n    // If the file worker is installed we would prefer to use the gridfs sa\n    // for scalability. We also default to gridfs if filesystem is not found\n\n    // Use the gridfs\n    FS.TempStore.Storage = new FS.Store.GridFS('_tempstore', { internal: true });\n  } else if (Package[\"cfs:filesystem\"]) {\n\n    // use the Filesystem\n    FS.TempStore.Storage = new FS.Store.FileSystem('_tempstore', { internal: true });\n  } else {\n    throw new Error('FS.TempStore.Storage is not set: Install cfs:filesystem or cfs:gridfs or set it manually');\n  }\n\n  FS.debug && console.log('TempStore is mounted on', FS.TempStore.Storage.typeName);\n}\n\nfunction mountFile(fileObj, name) {\n  if (!fileObj.isMounted()) {\n    throw new Error(name + ' cannot work with unmounted file');\n  }\n}\n\n// We update the fileObj on progress\nFS.TempStore.on('progress', function(fileObj, chunkNum, count, total, result) {\n  FS.debug && console.log('TempStore progress: Received ' + count + ' of ' + total + ' chunks for ' + fileObj.name());\n});\n\n// XXX: TODO\n// FS.TempStore.on('stored', function(fileObj, chunkCount, result) {\n//   // This should work if we pass on result from the SA on stored event...\n//   fileObj.update({ $set: { chunkSum: 1, chunkCount: chunkCount, size: result.size } });\n// });\n\n// Stream implementation\n\n/**\n * @method _chunkPath\n * @private\n * @param {Number} [n] Chunk number\n * @returns {String} Chunk naming convention\n */\n_chunkPath = function(n) {\n  return (n || 0) + '.chunk';\n};\n\n/**\n * @method _fileReference\n * @param {FS.File} fileObj\n * @param {Number} chunk\n * @private\n * @returns {String} Generated SA specific fileKey for the chunk\n *\n * Note: Calling function should call mountStorage() first, and\n * make sure that fileObj is mounted.\n */\n_fileReference = function(fileObj, chunk, existing) {\n  // Maybe it's a chunk we've already saved\n  existing = existing || tracker.findOne({fileId: fileObj._id, collectionName: fileObj.collectionName});\n\n  // Make a temporary fileObj just for fileKey generation\n  var tempFileObj = new FS.File({\n    collectionName: fileObj.collectionName,\n    _id: fileObj._id,\n    original: {\n      name: _chunkPath(chunk)\n    },\n    copies: {\n      _tempstore: {\n        key: existing && existing.keys[chunk]\n      }\n    }\n  });\n\n  // Return a fitting fileKey SA specific\n  return FS.TempStore.Storage.adapter.fileKey(tempFileObj);\n};\n\n/**\n * @method FS.TempStore.exists\n * @param {FS.File} File object\n * @returns {Boolean} Is this file, or parts of it, currently stored in the TempStore\n */\nFS.TempStore.exists = function(fileObj) {\n  var existing = tracker.findOne({fileId: fileObj._id, collectionName: fileObj.collectionName});\n  return !!existing;\n};\n\n/**\n * @method FS.TempStore.listParts\n * @param {FS.File} fileObj\n * @returns {Object} of parts already stored\n * @todo This is not yet implemented, milestone 1.1.0\n */\nFS.TempStore.listParts = function fsTempStoreListParts(fileObj) {\n  var self = this;\n  console.warn('This function is not correctly implemented using SA in TempStore');\n  //XXX This function might be necessary for resume. Not currently supported.\n};\n\n/**\n * @method FS.TempStore.removeFile\n * @public\n * @param {FS.File} fileObj\n * This function removes the file from tempstorage - it cares not if file is\n * already removed or not found, goal is reached anyway.\n */\nFS.TempStore.removeFile = function fsTempStoreRemoveFile(fileObj) {\n  var self = this;\n\n  // Ensure that we have a storage adapter mounted; if not, throw an error.\n  mountStorage();\n\n  // If fileObj is not mounted or can't be, throw an error\n  mountFile(fileObj, 'FS.TempStore.removeFile');\n\n  // Emit event\n  self.emit('remove', fileObj);\n\n  var chunkInfo = tracker.findOne({\n    fileId: fileObj._id,\n    collectionName: fileObj.collectionName\n  });\n\n  if (chunkInfo) {\n\n    // Unlink each file\n    FS.Utility.each(chunkInfo.keys || {}, function (key, chunk) {\n      var fileKey = _fileReference(fileObj, chunk, chunkInfo);\n      FS.TempStore.Storage.adapter.remove(fileKey, FS.Utility.noop);\n    });\n\n    // Remove fileObj from tracker collection, too\n    tracker.remove({_id: chunkInfo._id});\n\n  }\n};\n\n/**\n * @method FS.TempStore.removeAll\n * @public\n * This function removes all files from tempstorage - it cares not if file is\n * already removed or not found, goal is reached anyway.\n */\nFS.TempStore.removeAll = function fsTempStoreRemoveAll() {\n  var self = this;\n\n  // Ensure that we have a storage adapter mounted; if not, throw an error.\n  mountStorage();\n\n  tracker.find().forEach(function (chunkInfo) {\n    // Unlink each file\n    FS.Utility.each(chunkInfo.keys || {}, function (key, chunk) {\n      var fileKey = _fileReference({_id: chunkInfo.fileId, collectionName: chunkInfo.collectionName}, chunk, chunkInfo);\n      FS.TempStore.Storage.adapter.remove(fileKey, FS.Utility.noop);\n    });\n\n    // Remove from tracker collection, too\n    tracker.remove({_id: chunkInfo._id});\n  });\n};\n\n/**\n * @method FS.TempStore.createWriteStream\n * @public\n * @param {FS.File} fileObj File to store in temporary storage\n * @param {Number | String} [options]\n * @returns {Stream} Writeable stream\n *\n * `options` of different types mean differnt things:\n * * `undefined` We store the file in one part\n * *(Normal server-side api usage)*\n * * `Number` the number is the part number total\n * *(multipart uploads will use this api)*\n * * `String` the string is the name of the `store` that wants to store file data\n * *(stores that want to sync their data to the rest of the files stores will use this)*\n *\n * > Note: fileObj must be mounted on a `FS.Collection`, it makes no sense to store otherwise\n */\nFS.TempStore.createWriteStream = function(fileObj, options) {\n  var self = this;\n\n  // Ensure that we have a storage adapter mounted; if not, throw an error.\n  mountStorage();\n\n  // If fileObj is not mounted or can't be, throw an error\n  mountFile(fileObj, 'FS.TempStore.createWriteStream');\n\n  // Cache the selector for use multiple times below\n  var selector = {fileId: fileObj._id, collectionName: fileObj.collectionName};\n\n  // TODO, should pass in chunkSum so we don't need to use FS.File for it\n  var chunkSum = fileObj.chunkSum || 1;\n\n  // Add fileObj to tracker collection\n  tracker.upsert(selector, {$setOnInsert: {keys: {}}});\n\n  // Determine how we're using the writeStream\n  var isOnePart = false, isMultiPart = false, isStoreSync = false, chunkNum = 0;\n  if (options === +options) {\n    isMultiPart = true;\n    chunkNum = options;\n  } else if (options === ''+options) {\n    isStoreSync = true;\n  } else {\n    isOnePart = true;\n  }\n\n  // XXX: it should be possible for a store to sync by storing data into the\n  // tempstore - this could be done nicely by setting the store name as string\n  // in the chunk variable?\n  // This store name could be passed on the the fileworker via the uploaded\n  // event\n  // So the uploaded event can return:\n  // undefined - if data is stored into and should sync out to all storage adapters\n  // number - if a chunk has been uploaded\n  // string - if a storage adapter wants to sync its data to the other SA's\n\n  // Find a nice location for the chunk data\n  var fileKey = _fileReference(fileObj, chunkNum);\n\n  // Create the stream as Meteor safe stream\n  var writeStream = FS.TempStore.Storage.adapter.createWriteStream(fileKey);\n\n  // When the stream closes we update the chunkCount\n  writeStream.safeOn('stored', function(result) {\n    // Save key in tracker document\n    var setObj = {};\n    setObj['keys.' + chunkNum] = result.fileKey;\n    tracker.update(selector, {$set: setObj});\n\n    // Get updated chunkCount\n    var chunkCount = FS.Utility.size(tracker.findOne(selector).keys);\n\n    // Progress\n    self.emit('progress', fileObj, chunkNum, chunkCount, chunkSum, result);\n\n    // If upload is completed\n    if (chunkCount === chunkSum) {\n      // We no longer need the chunk info\n      var modifier = { $set: {}, $unset: {chunkCount: 1, chunkSum: 1, chunkSize: 1} };\n\n      // Check if the file has been uploaded before\n      if (typeof fileObj.uploadedAt === 'undefined') {\n        // We set the uploadedAt date\n        modifier.$set.uploadedAt = new Date();\n      } else {\n        // We have been uploaded so an event were file data is updated is\n        // called synchronizing - so this must be a synchronizedAt?\n        modifier.$set.synchronizedAt = new Date();\n      }\n\n      // Update the fileObject\n      fileObj.update(modifier);\n\n      // Fire ending events\n      var eventName = isStoreSync ? 'synchronized' : 'stored';\n      self.emit(eventName, fileObj, result);\n\n      // XXX is emitting \"ready\" necessary?\n      self.emit('ready', fileObj, chunkCount, result);\n    } else {\n      // Update the chunkCount on the fileObject\n      fileObj.update({ $set: {chunkCount: chunkCount} });\n    }\n  });\n\n  // Emit errors\n  writeStream.on('error', function (error) {\n    FS.debug && console.log('TempStore writeStream error:', error);\n    self.emit('error', error, fileObj);\n  });\n\n  return writeStream;\n};\n\n/**\n  * @method FS.TempStore.createReadStream\n  * @public\n  * @param {FS.File} fileObj The file to read\n  * @return {Stream} Returns readable stream\n  *\n  */\nFS.TempStore.createReadStream = function(fileObj) {\n  // Ensure that we have a storage adapter mounted; if not, throw an error.\n  mountStorage();\n\n  // If fileObj is not mounted or can't be, throw an error\n  mountFile(fileObj, 'FS.TempStore.createReadStream');\n\n  FS.debug && console.log('FS.TempStore creating read stream for ' + fileObj._id);\n\n  // Determine how many total chunks there are from the tracker collection\n  var chunkInfo = tracker.findOne({fileId: fileObj._id, collectionName: fileObj.collectionName}) || {};\n  var totalChunks = FS.Utility.size(chunkInfo.keys);\n\n  function getNextStreamFunc(chunk) {\n    return Meteor.bindEnvironment(function(next) {\n      var fileKey = _fileReference(fileObj, chunk);\n      var chunkReadStream = FS.TempStore.Storage.adapter.createReadStream(fileKey);\n      next(chunkReadStream);\n    }, function (error) {\n      throw error;\n    });\n  }\n\n  // Make a combined stream\n  var combinedStream = CombinedStream.create();\n\n  // Add each chunk stream to the combined stream when the previous chunk stream ends\n  var currentChunk = 0;\n  for (var chunk = 0; chunk < totalChunks; chunk++) {\n    combinedStream.append(getNextStreamFunc(chunk));\n  }\n\n  // Return the combined stream\n  return combinedStream;\n};\n"]}